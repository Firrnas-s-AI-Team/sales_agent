import streamlit as st
import os
import glob
import json
from dotenv import load_dotenv
load_dotenv()
from langchain_community.document_loaders import JSONLoader
from langchain.docstore.document import Document
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.memory import ChatMessageHistory
from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# Directories
BASE_DIR = r"E:\Singularity\Sales_Aget_project\Dataset\New folder\LLM_\LLM_\Office-OF"
base_imag = r'E:\Singularity\Sales_Aget_project\Dataset\New folder\LLM_\LLM_'

# Function to get categories
def get_categories():
    return [d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d))]

# Function to get products
def get_products(category):
    category_path = os.path.join(BASE_DIR, category)
    return [d for d in os.listdir(category_path) if os.path.isdir(os.path.join(category_path, d))] if os.path.exists(category_path) else []

# Function to load product details
def load_product_details(category, product):
    product_path = os.path.join(BASE_DIR, category, product)
    json_files = glob.glob(os.path.join(product_path, "*.json"))
    if json_files:
        loader = JSONLoader(
            file_path=json_files[0],
            jq_schema=".[]",
            text_content=False,
            metadata_func=lambda record, index: {"source": "json_data", "index": index}
        )
        return loader.load()
    return {"error": "Product details not found."}

# Streamlit UI
st.set_page_config(page_title="Mobica Sales Chatbot", layout="wide")
st.title("ğŸ›‹ï¸ Welcome to Mobica - Premium Furniture Solutions")
st.sidebar.header("ğŸ” Explore Our Products")

categories = get_categories()
category = st.sidebar.selectbox("ğŸ“‚ Select a Category", categories)
products = get_products(category) if category else []
product = st.sidebar.selectbox("ğŸ“¦ Select a Product", products)

docs, product_images = [], {}
if product:
    docs = load_product_details(category, product)
    for doc in docs:
        content = json.loads(doc.page_content)
        image_paths = content.get('Image Paths', [])
        if image_paths:
            product_images[content['Product Name']] = [os.path.join(base_imag, img) for img in image_paths]

# Chatbot Section
st.subheader("ğŸ¤– Mobica Sales Chatbot")
chat_history = ChatMessageHistory()
embeddings = OllamaEmbeddings(model="nomic-embed-text")
vectorstore = FAISS.from_documents([Document(page_content=json.dumps(json.loads(doc.page_content))) for doc in docs], embedding=embeddings)
retriever = vectorstore.as_retriever()

groq_api_key = os.getenv('Groq_API_Key')
llm = ChatGroq(groq_api_key=groq_api_key, model='mixtral-8x7b-32768')

# prompt_template ="""Ø£Ù†Øª Ø´ØºØ§Ù„ ÙˆÙƒÙŠÙ„ Ù…Ø¨ÙŠØ¹Ø§Øª Ø¬Ø§ÙˆØ¨ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù„ÙŠ Ù„ÙŠÙ‡Ø§ Ø¹Ù„Ø§Ù‚Ø©  Ø¨Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª.
# Ù…Ù† Ø®Ù„Ø§Ù„ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù‡Ø§Ø¯ÙŠÙƒ Ù…ÙˆØ§ØµÙØ§Øª ÙƒÙ„ Ù…Ù†ØªØ¬ ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ 

# Ø§Ù„Ø³ÙŠØ§Ù‚: {context}
# Ø§Ù„Ø³Ø¤Ø§Ù„: {question}
# Ø¬Ø§ÙˆØ¨ Ø¹Ù„ÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ø§Ù„Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ© 
# """

prompt_template = """
Ø¥Ù†Øª Ø¯Ù„ÙˆÙ‚ØªÙŠ Ø´ØºØ§Ù„ ÙˆÙƒÙŠÙ„ Ù…Ø¨ÙŠØ¹Ø§Øª Ù…Ø­ØªØ±ÙØŒ Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ:
Ù¡- ØªØ¬Ø§ÙˆØ¨ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù„ÙŠ Ù„ÙŠÙ‡Ø§ Ø¹Ù„Ø§Ù‚Ø© Ø¨Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
Ù¢- ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ© ÙÙŠ ÙƒÙ„ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ
Ù£- ØªØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø²ÙŠ (finished electrostatic powder coated) Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
Ù¤- ØªØ´Ø±Ø­ Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø³Ù‡Ù„ ÙˆØ¨Ø³ÙŠØ·
Ù¥- ØªØªÙƒÙ„Ù… Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ù†Ø¯ÙˆØ¨ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ù…ØµØ±ÙŠ

âœ… **ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙƒØ§Ù„ØªØ§Ù„ÙŠ:**
- **Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙØ§Ø±Øº Ø£Ùˆ ØºÙŠØ± ÙˆØ§Ø¶Ø­ØŒ Ù„Ø§ ØªØ³ØªØ±Ø¬Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ ÙÙ‚Ø· Ø§Ø·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­Ø§Ù‹ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø¨Ø³ÙŠØ·ØŒ Ù…Ø«Ø§Ù„:**  
  - "Ù…Ø¹Ù„Ø´ ÙŠØ§ ÙÙ†Ø¯Ù…ØŒ Ù…Ù…ÙƒÙ† ØªÙˆØ¶Ø­ Ø³Ø¤Ø§Ù„Ùƒ Ø£ÙƒØªØ±ØŸ"  
  - "ÙŠØ§Ø±ÙŠØª ØªÙƒØªØ¨ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ø¹Ù„Ø´Ø§Ù† Ø£Ù‚Ø¯Ø± Ø£Ø³Ø§Ø¹Ø¯Ùƒ!"   
ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©ØŒ Ù„Ø§ ØªØ¶ÙŠÙ Ø£ÙŠ ØªÙØ§ØµÙŠÙ„ Ø¹Ù† Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª

- **Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙŠØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ù…Ù†ØªØ¬Ø§ØªØŒ Ø¬Ø§ÙˆØ¨ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ù†Ø¸Ù…Ø© Ø¨Ø§Ù„Ù†Ù…Ø· Ø§Ù„ØªØ§Ù„ÙŠ:**  
  - **Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©**  
  - **Ø§Ù„Ù…Ù‚Ø§Ø³Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©**  
  - **Ø§Ù„Ø¥Ø¶Ø§ÙØ§Øª Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©** 


- **Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ù† Ø§Ù„Ø³Ø¹Ø±ØŒ ÙˆØ¶Ù‘Ø­ Ø£Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ Ø¨Ø£ÙŠ Ù…Ù† Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:**  
  - "ÙŠØ§ ÙÙ†Ø¯Ù…ØŒ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ø´ Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ Ù„ÙƒÙ† Ù…Ù…ÙƒÙ† Ø£Ù‚ÙˆÙ„Ùƒ ÙƒÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø¹Ù† Ø§Ù„Ù…Ù†ØªØ¬."

Ø·Ø±ÙŠÙ‚Ø© ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
â€¢ Ù†Ø¸Ù… Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª ÙÙŠ Ù†Ù‚Ø· ÙˆØ§Ø¶Ø­Ø© ØªØ­Øª Ø¹Ù†Ø§ÙˆÙŠÙ† Ø±Ø¦ÙŠØ³ÙŠØ©:
  - Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
  - Ø§Ù„Ù…Ù‚Ø§Ø³Ø§Øª Ø£Ùˆ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù…ØªØ§Ø­Ø©
  - Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª
  - Ø§Ù„Ø¥Ø¶Ø§ÙØ§Øª Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©

â€¢ Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ù‚Ø§Ø³Ø§Øª Ø£Ùˆ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø¸Ù…
â€¢ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ù„Ù„ØªÙˆØ¶ÙŠØ­:
  - Ø§Ù„Ù†Ù‚Ø· (â€¢) Ù„Ù„Ù…Ù…ÙŠØ²Ø§Øª
  - Ø§Ù„Ø´Ø±Ø·Ø© (-) Ù„Ù„ØªÙØ§ØµÙŠÙ„
  - Ø§Ù„Ø£Ù‚ÙˆØ§Ø³ () Ù„Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ©

Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¨ØªØ§Ø¹ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª: {context}
Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨ØªØ§Ø¹Ùƒ: {question}

Ù„Ø§Ø²Ù… ØªØ¬Ø§ÙˆØ¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ© ÙˆØªØ³ØªØ®Ø¯Ù… ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø²ÙŠ:
- "Ø·ÙŠØ¨ Ù…Ù…ÙƒÙ† Ø£Ù‚ÙˆÙ„Ùƒ"
ÙˆØªØ­Ø· Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø³ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
"""
 
prompt = ChatPromptTemplate.from_template(prompt_template)
output_parser = StrOutputParser()

rag_chain = ({
    "context": retriever,
    "question": RunnablePassthrough(),
    "chat_history": RunnableLambda(lambda _: "\n".join([f"{msg.role}: {msg.content}" for msg in chat_history.messages])),
} | prompt | llm | output_parser)

question = st.text_input("ğŸ’¬ Ask a Question about the Product:")
if question:
    response = rag_chain.invoke({"question": question})
    st.markdown(f"**ğŸ—¨ï¸ Response:** {response}")
    chat_history.add_user_message(question)
    chat_history.add_ai_message(response)
    
    for product_name in product_images:
        if product_name.lower() in response.lower():
            for img_path in product_images[product_name]:
                if os.path.exists(img_path):
                    st.image(img_path, caption=product_name, use_container_width=True)
